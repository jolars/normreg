\section{Experiments}\label{sec:experiments}

In the following sections we present the results of our experiments. In
\Cref{sec:experiments-lassoridge}, we focus on normalization in the cases of the lasso and
ridge regression. In \Cref{sec:experiments-elasticnet}, we turn to the elastic net,
focusing on solving class balance bias via penalty weighting.

For all simulated data we generate our response vector according to \(\vec{y} =
\mat{X}\vec{\beta}^* + \vec{\varepsilon},\) with \(\vec{\varepsilon} \sim \normal(\vec{0},
\sigma_\varepsilon^2 \mat{I})\). We consider two types of features: binary and quasi-normal
features. To generate binary vectors, we sample \(\ceil{nq_j}\) indexes uniformly at random
without replacement from \(\{1,2,\dots,n\}\) and set the corresponding elements to one and
the remaining ones to zero. To generate quasi-normal features, we generate a linear
sequence \(\vec{w}\) with \(n\) values from \(10^{-4}\) to \(1 - 10^{-4}\), set \(x_{ij} =
\cdf^{-1}(w_i)\), and then shuffle the elements of \(\vec{x}_j\) uniformly at random.

We use a coordinate descent solver to fit the elastic net, which we have based on the
algorithm outlined by \citet{friedman2010}. All experiments were coded using the Julia
programming language~\citep{bezanson2017} and the code is available at
\url{https://github.com/jolars/normreg}.

\subsection{Normalization in the Lasso and Ridge Regression}\label{sec:experiments-lassoridge}

In this section we consider fitting the lasso and ridge regression to normalized data sets.
To normalize the data, we use standardization (centering and scaling by mean and standard
deviation) for all our quasi-normal features. For binary features, we center by mean and
scale by \(s_j = (q_j-q_j^2)^\delta\), where \(\delta = 0\) corresponds to no scaling,
\(\delta = 1/2\) to standardization, and \(\delta = 1\) to variance scaling.

\subsubsection{Variability and Bias in Estimates}\label{sec:experiments-varbias}

In our first experiment, we consider fitting the lasso to a simulated data set with
\(n=500\) observations and \(p = \num{1000}\) features, out of which the first 20 features
correspond to signals, with \(\beta_j^*\) decreasing linearly from 1 to 0.1. We introduce
dependence between the features by copying the first \(\ceil{\rho n/2}\) values from the
first feature to each of the following features. In addition, we set the class balance of
the first 20 features so that it decreases linearly on a log-scale from 0.5 to 0.99. We
estimate the regression coefficients using the lasso, setting \(\lambda_1 = 2
\sigma_\varepsilon \sqrt{2 \log p }\) and compare the estimates to \(\bm{\beta}^*\). We run
the experiment for 50 iterations in each case and aggregate the results by reporting means
and standard deviations.

The results~(\Cref{fig:binary-decreasing}) show that class balance has considerable effect,
particularly in the case of no scaling (\(\delta = 0\)), which corroborates our theoretical
results from \Cref{sec:theory-binary-features}. At \(q_j=0.99\), for instance, the estimate
(\(\hat{\beta}_{20}\)) is consistently zero when \(\delta = 0\). There is a similar effect
also in the case of standardization (\(\delta = 1/2\)), but it is less pronounced. For
\(\delta=1\) (variance scaling), we see that the effect of class balance on the estimates
is, if anything, the reverse when the class imbalance is severe. What is also clear is that
the variance of the estimates increase with class imbalance and that this effect increases
together with \(\delta\). The level of correlation between the features introduces
additional variance in the estimates but also seems to increase the effect of class
imbalance in the cases when \(\delta = 0\) or \(1/2\).

\begin{figure}[htpb]
  \centering
  \includegraphics[]{plots/binary_decreasing_small.pdf}
  \caption{%
    Estimates of the regression coefficients from the lasso, \(\hat{\vec{\beta}}\), for the
    first 30 coefficients in the experiment. All of the features are binary and the first 20
    features correspond to true signals with \(\beta_j^* = 2\) and geometrically decreasing
    class balance from 0.5 to 0.99. The remaining features have class balance \(q_j \in [0.5,
      0.99]\) distributed linearly among the features. The plot shows means and standard
    deviations averaged over 50 iterations.} \label{fig:binary-decreasing}
\end{figure}

\subsubsection{Normalization as a Hyperparameter}\label{sec:experiments-hyperparameter}

% TODO: consider reparameterizing with respect to lambda/delta
Our previous results (particularly those from \Cref{sec:predictive-performance}) suggest
that the choice of normalization matters for predictive performance. These results have
relied on knowledge of the measurement error (signal-to-noise ratio), which we do not have
reliable estimates of in practice (at least not in the high-dimensional context). An
alternative that, however, comes naturally as a consequence of our particular
parameterization using \(\delta\), is to treat the choice of normalization as a
hyperparameter and optimize over it. This is the approach we take in this experiment.

We set up a grid of \(\lambda\) values as in \Cref{sec:predictive-performance} and create a
linearly spaced grid of \(\delta\) values in \([0, 1]\). We split the data into a equal
training and validation set splits and for each point in this two-dimensional grid fit the
lasso or ridge to the training set and compute validation set error. We use three data
sets: \data{a1a}~\citep{becker1996}, \data{rhee2006}~\citep{rhee2006}, and
\data{w1a}~\citep{platt1998}. See \Cref{sec:data-summary} for details about these data
sets.

We show estimated level curves of validation set error in terms of normalized mean-squared
error (NMSE), in \Cref{fig:hyperopt-contours}. For \data{a1a}, the lasso is generally quite
insensitive to the type of normalization, even if the optimal value is around 0.2. For
ridge regression, lower values of \(\delta\) clearly work better. With the \data{w1a} data
set, however, the relationship is flipped in the case of ridge regression and the optimal
value is approximately 0.8. In the case of the lasso (for \(\data{w1a}\)), a value around
0.5 is optimal and low values (little scaling) yield worse prediction errors. Finally, for
\data{rhee2006}, the lasso is again insensitive to normalization type. This is not the case
for ridge, however, where a value around 0.2 is optimal and high values of \(\delta\) yield
worse prediction errors.

\begin{figure}[htpb]
  \centering
  \includegraphics[]{plots/hyperopt_surfaces.pdf}
  \caption{%
    Contour plots of normalized mean-squared error (NMSE) for the hold-out validation set
    across a grid of \(\delta\) and \(\lambda\) values for ridge regression and the lasso. The
    dotted path shows the smallest NMSE as a function of \(\lambda\). The dot marks the
    combination with the smallest error.
  }
  \label{fig:hyperopt-contours}
\end{figure}

We would like to point out that there is a dependency between \(\lambda\) and \(\delta\)
that make it difficult to interpret the relationship between them and the error. This comes
from the fact that scaling with a smaller value (as in \(\delta = 1\)) increases the sizes
of the vectors, which means that the level of penalization is relaxed, relatively speaking.

In \Cref{sec:predictive-performance}, we consider predictive performance for simulated data
under various signal-to-noise ratios, again showing that normalization has an impact on
prediction properties.

\subsubsection{Mixed Data}\label{sec:experiments-mixed-data}

In \Cref{sec:mixed-data}, we discovered that special care needs to be taken when
normalizing mixed data. In this experiment, we construct a quasi-normal feature with mean
zero and standard deviation 1/2 and a binary feature with varying class balance \(q_j\). We
set the signal-to-noise ratio to 0.5 and generate our response vector \(\vec{y}\) as
before, with \(n = \num{1000}\). These features are constructed so that their effects are
comparable under the notion of comparability that we introduce in \Cref{sec:mixed-data},
using \(\kappa = 2\). In order to preserve the comparability for the baseline case \(q_0 =
1/2\), we use the scaling introduced in \Cref{sec:mixed-data}, which leads to \(s_j = 2
\times (1/4)^{1-\delta}(q_j-q_j^2)^\delta\). For lasso and ridge, respectively, we set the
level of penalization to \(\lambda_\text{max}/2\) and
\(2\lambda_\text{max}\).\footnote{This makes the level of regularization comparable between
  the two cases.}

The results~(\Cref{fig:lasso-ridge-comparison}) reflect our theoretical results from
\Cref{sec:theory}. In the case of the lasso, we need \(\delta =1\) to avoid the effect of
class imbalance, whereas for ridge we instead need \(\delta =1/2\) (standardization). As
our theory suggests, this extra scaling mitigates this class-balance dependency at the cost
of added variance. Note that we do not see the bias reduction that we observed in our
theoretical results for high \(q_j\) values and \(\delta \geq 1/2\) in
\Cref{fig:lasso-ridge-comparison}. This is related to the error term (signal-to-noise
ratio) and level of \(q_j\). We would need stronger class imbalance and larger error for
the effect to show up here.

\begin{figure}[htpb]
  \centering
  \includegraphics{plots/mixed_data.pdf}
  \caption{%
    Lasso and ridge estimates for a two-dimensional problem where one feature is a binary
    feature with class balance \(q_j\) (\(\bernoulli(q_j)\)) and the other is a quasi-normal
    feature with standard deviation 1/2, \(\normal(0, 0.5)\). Here, we have \(n = \num{1000}\)
    observations. The signal-to-noise ratio is 0.5 In every case, we standardize the normal
    feature. The binary feature, meanwhile, is centered by its mean and scaled by
    \((q_j-q_j^2)^\delta\). The experiment is run for 50 iterations and we aggregate and report
    means and standard deviations of the estimates.
  }
  \label{fig:lasso-ridge-comparison}
\end{figure}

\subsubsection{Interactions}\label{sec:experiments-interactions}

Here we study the effects of normalization and class balance on interactions when using the
lasso. Our example consists of a two-feature problem with an added interaction term given
by \(x_{i3} = x_{i1}x_{i2}\). The first feature is binary with class balance \(q\) and the
second quasi-normal with standard deviation 0.5. We set \(n=1000\), specify \(\lambda_1 =
n/4\). Then, we standardize the normal feature and normalize the binary feature by
centering by its mean and scaling by \(\kappa (q - q^2)\), with \(\kappa = 2\). We consider
two different strategies for choosing \(s_3\): in the first strategy, which we call
\emph{Strateg 1}, we simply standardize the resulting interaction feature.
% TODO: make a reference to where this is done
In the second strategy, \emph{Strategy 2} we center with mean and scale with \(s_1s_2\)
(the product of the scales of the binary and normal features).

The results~(\Cref{fig:interactions}) show that the only strategy that consistently picks
the correct model is strategy 2, in which the scale is the product of the scales of
\(\bm{x}_1\) and \(\bm{x}_2\). Strategy 1, meanwhile, selects the correct model as long as
the class balance of the binary feature is close to 1/2, but fails to pick up on the
interaction effect if the binary feature is too imbalanced, and in general shrinks it too
much. Strategy 2, in which we base our scale only on the subset of observations for which
the binary feature is 1, only seems to perform reasonably well when \(q\) is close to zero,
as it converges towards strategy 3.

\begin{figure}[htpb]
  \centering
  \includegraphics[]{plots/interactions-classbalance-small.pdf}
  \caption{%
    Lasso estimates for a three-feature problem where the third feature is an
    interaction term between the first two features. The first feature is
    binary with class balance \(q\) and the second is quasi-normal with
    standard deviation 0.5. The signal-to-noise ratio is 1. The experiment was
    run for 50 iterations and we aggregate and report means across all
    iterations. Please see \Cref{sec:experiments-interactions} for information
    about the different strategies and \Cref{fig:interactions-full}
    (\Cref{sec:additional-experiments-interactions}) for plots showing multiple
    combinations of true coefficients.
  }
  \label{fig:interactions}
\end{figure}

\subsection{The Weighted Elastic Net}\label{sec:experiments-elasticnet}

In this section, we focus on the weighted elastic net, which, as we showed in
\Cref{sec:weighted-elasticnet}, can be used as an alternative to normalization to correct
for class balance bias in the elastic net. To simplify the presentation, we parameterize
the elastic net as \(\lambda_1 = \alpha \lambda \) and \(\lambda_2 = (1-\alpha) \lambda\),
so that \(\alpha\) controls the balance between the two penalties. We conduct an experiment
with the same setup as in \Cref{sec:experiments-mixed-data}, but here we use the weighted
elastic net instead with \(\alpha \in \{0.25, 0.75\}\). We use \(n=1000\) and run the
simulations fro 50 iterations for different values of \(\omega\), using the weights \(u_j =
v_j = (q_j - q_j^2)^{\omega}\), as we suggested in \Cref{sec:binary-weighting}. Our results
(\Cref{fig:mixed-data-elnet}) show that \(\omega = 1\) leads to seemingly unbiased
estimates of the binary feature at the cost of increased variance.

\begin{figure}[htpb]
  \centering
  \includegraphics{plots/mixed_data_elnet.pdf}
  \caption{%
    Weighted elastic net estimates for a two-dimensional problem where one feature is a binary
    feature with class balance \(q\) (\(\bernoulli(q)\)), and the other is a quasi-normal
    feature with standard deviation 1/2 (\(\normal(0, 0.5)\)). Here, we have \(n = \num{1000}\)
    observations. The signal-to-noise ratio is 0.5. In every case, we standardize the normal
    feature. The binary feature, meanwhile, is centered by its mean and scaled by
    \((q-q^2)^\delta\). The experiment was run for 50 iterations and we aggregate and report
    means and standard deviations of the estimates. \label{fig:mixed-data-elnet}
  }
\end{figure}

