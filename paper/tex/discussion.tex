\section{Practical Recommendations}

The results presented in this paper directly concern practitioners working with regularized
regression on data with binary features. In general, we want to stress that the choice of
normalization affects not only the computational aspects of fitting the model, but also the
model itself. The bias introduced by ridge, lasso, and elastic net regression depends on
the normalization scheme used, and does so in a penalty-specific manner, which means there
exists no one-size-fits-all solution. In the following sections, we provide some concrete
guidelines for practitioners on how to normalize.

\subsection{Feature Selection}

We have shown that, to avoid bias against class-imbalanced binary features, we need to
scale them with their standard deviations for ridge regression and with their variances for
the lasso. Therefore, if the goal is feature selection and the cost of missing a relevant
feature is high, then scaling with variance may be preferable. Scaling with variance,
however, will increase the variability of the estimates, which means that the choice of
normalization is a bias--variance trade-off. Naturally, this also means that the size of
the dataset matters: with more data, users may be able to afford the increased variance
that comes with scaling with variance.

\subsection{Prediction}

If the goal is prediction, then scaling with standard deviation or even not scaling at
all\footnote{Or equivalently, using max--abs or min--max normalization.} will typically
prove the better choice. If the practitioner can afford the computational cost, we also
recommend treating normalization as a hyper-parameter optimization problem, which will
allow users to look for a normalization scheme that is optimal for their specific dataset
and prediction task. The user can, for instance, cross-validate over a few common
normalization schemes or alternatively use the parameterization through $\delta$ that we
have proposed in \Cref{sec:theory-binary-features}.

\subsection{The Elastic Net}

For ridge and lasso regression, the class imbalance can be controlled through the choice of
normalization. This is not, however, the case for the elastic net. In this case, we
therefore recommend users scale the penalty weights instead of the features themselves, as
described in \Cref{sec:binary-weighting}. We believe this is a more intuitive approach,
given that the elastic net is a mix of two different norms, which interact with the
features' scales in separate ways.

\subsection{Mixed Data}

For mixed data, the choice of normalization is tricky since it implicitly affects the
relative penalization of binary and normal features. Practitioners need to decide how they
want to treat binary features relative to normal features. We discuss this topic in
\Cref{sec:mixed-data} and introduce the parameter $\kappa$ that allows practitioners to
control this effect through the normalization strategy. While we provide no concrete
recommendations for setting this parameter, we believe that awareness of this implicit
relationship is important.

\subsection{Interactions}

Interactions introduce another layer of complexity because normalization will affect the
correlation between the original features and their interaction terms. We recommend always
centering the features before creating the interaction terms, since the means of the
features otherwise affect the estimates. Second, we suggest a new type of normalization for
interaction features, which is to scale them based on the \emph{product} of the scales of
the normalized original features. We have shown that this can mitigate the class-balance
bias effect.

\section{Discussion}

% TODO: Consider reducing the content here now that the introduction contains
% a summary of our contributions

This is the first paper to study the effects of normalization in lasso, ridge, and elastic
net regression with binary data. We have discovered that the class balance (proportion of
ones) of these binary features has a pronounced effect on both lasso and ridge estimates
and that this effect depends on the type of normalization used. For the lasso, for
instance, features with large class imbalances stand little chance of being selected if the
binary features are standardized or, to an even greater extent, if they are not scaled at
all---even if their relationships with the response are strong. Not scaling binary features
is a common approach in practice, for instance recommended in the \pkg{scikit-learn}
documentation when the data is sparse~\citep{scikit-learndevelopers2025}. As is
standardization, which is the default in many software packages for the lasso, such as
\pkg{glmnet}~\citep{friedman2010}, as well as the practice taken by countless applications
in research. All in all, this means that the class-balance bias effect is likely pervasive
in practice and risks having already influenced the conclusions drawn in analyses of many
datasets.

The driver of this bias is the relationship between the variance of the feature and type of
normalization. This works as expected for normally distributed features. But for binary
features it means that a one-unit change is treated differently depending on the
corresponding feature's class balance, which we believe may surprise some. We have,
however, shown that scaling binary features with standard deviation in the case of ridge
regression and variance in the case of the lasso mitigates this effect, but that doing so
comes at the price of increased variance. This effectively means that the choice of
normalization constitutes a bias--variance trade-off.

We have also studied the case of mixed data: designs that include both binary and normally
distributed features~(\Cref{sec:mixed-data}). In this setting, our first finding is that
there is an implicit relationship between the choice of normalization and the manner in
which regularization affects binary vis-Ã -vis normally distributed features, even when the
binary feature is perfectly balanced. The choice of max--abs normalization, for instance,
leads to a specific weighting of the effects of binary features relative to those of normal
features.

For interactions between binary and normal features~(\Cref{sec:experiments-interactions}),
our conclusion is that the interaction feature---contrary to what recent literature on
interactions in the lasso recommends---should be scaled with the \emph{product} of the
standard deviation of the normal feature and variance of the binary feature to avoid this
effect of class imbalance. We have not seen this recommendation in the literature before,
but it is a natural extension of our other results.

We note that our theoretical results are limited by a few assumptions: 1) a fixed feature
matrix \(\bm{X}\), 2) normal and independent errors, and 3) orthogonal features. The first
and second of these assumptions are standard in the literature. The third assumption on
orthogonality, however, is strong and rarely satisfied in practice. Yet, as we show in
\Cref{sec:orthogonality-assumption} and our experiments, the assumption does not in fact
appear to be restrictive for our results, which, at least empirically, hold under much more
general settings. We have also focused on the case of binary and continuous features here,
but are convinced that categorical features are also of interest and might raise additional
challenges with respect to normalization. Finally, most of our results are restricted to
least-squares loss, but since all generalized linear models (GLMs) are parameterized by the
linear predictor, which we have shown to depend directly on class balance, we believe that
our results are also relevant for other loss functions. Our initial results in
\Cref{sec:normalization-tuning} seem to support this claim, but we defer further
investigation of this to future work.

Regularized regression models are widely used in practice, and are staples of popular
machine learning and statistical software packages such as
\pkg{glmnet}~\citep{friedman2010}, \pkg{scikit-learn}~\citep{pedregosa2011},
\pkg{mlpack}~\citep{curtin2023}, \pkg{skglm}~\citep{bertrand2022},
\pkg{LIBLINEAR}~\citep{fan2008a}, and \pkg{MATLAB}~\citep{themathworksinc.2022}. Our
results suggest that the choice of normalization is an important aspect of using these
models that, in spite of the popularity of these methods, has so far been overlooked. We
hope that our results will motivate researchers and practitioners to consider the choice of
normalization more carefully in the future.
