\section{Discussion}%
\label{sec:discussion}

We have studied the effects of normalization in lasso, ridge, and elastic net regression
with binary data---an issue that has so far not been studied. We have discovered the class
balance (proportion of ones and zeros) of these binary features have a pronounced effect on
both lasso and ridge estimates and that this effect depends on the type of normalization
used. For the lasso, for instance, features with large class imbalances stand little chance
of being selected if the features are standardized, even when their relationships with the
response are strong.

The driver of this result is the relationship between the variance of the feature and type
of normalization. This works as expected for normally distributed features. But for binary
features it means that a one-unit change is treated differently depending on the
corresponding feature's class balance, which we believe may be surprising to some. We have,
however, shown that scaling binary features with standard deviation in the case of ridge
regression and variance in the case of the lasso mitigates this effect, but that doing so
comes at the price of increased variance. This effectively means that the choice of
normalization constitutes a bias--variance trade-off.

% To study these effects, we have introduced the scaling parameterization $s_j = (q_j -
%   q_j^2)^\delta$, which includes the cases \(\delta=0\) (no scaling, as in max--abs and
% min--max normalization), \(\delta = 1/2\) (standard deviation scaling, as in
% standardization), and \(\delta=1\) (variance scaling). As far as we know, variance scaling
% has not been considered in the literature before. Our results demonstrate that the choice
% of \(\delta\) affects the lasso, ridge, and elastic net estimates both with respect to
% feature selection and predictive performance and suggests that there is benefit to choosing
% the normalization type via hyper-parameter optimization.

We have also studied the case of mixed data: designs that include both binary and normally
distributed features~(\Cref{sec:mixed-data}). In this setting, our first finding is that
there is an implicit relationship between the choice of normalization and the manner in
which regularization affects binary viz-a-viz normally distributed features, even when the
binary feature is perfectly balances. The choice of max--abs normalization, for instance,
carries a specific assumption about how the effect of a binary feature should be compared
to that of a normally distributed feature.

When it comes to the case of simple interactions between binary and normal features
features~(\Cref{sec:experiments-interactions}), our conclusions are that the interaction
feature should be computed after centering both the binary and normal feature and that
scaling with the product of the standard deviation and \((q-q^2)\) mitigates the class
balance bias in this case.

Finally, note that our theoretical results are limited by several assumptions: 1) a fixed
feature matrix \(\mat{X}\), 2) orthogonal features, and 3) normal and independent errors.
In future studies, it would be interesting to relax these assumptions and study the effects
of normalization in a more general setting. Finally, we have also focused on the case of
binary and continuous features here, but we are convinced that categorical features are
also of interest and might raise additional challenges with respect to normalization.
